{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c0315d-979c-4249-9000-b1942623456d",
   "metadata": {},
   "source": [
    "# REVIEW SENTIMENT CLASSIFIER: POSITIVE OR NEGATIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8479f9d-2f15-4a6e-b15f-8c9cb761c8d3",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    " - With the growing volume of customer reviews , businesses face challenges in quickly extracting actionable insights from feedback . Manual sentiment analysis is time consuming and prone to errors. An automated solution to classify reviews as positive or negative can enable faster decision making , improve customer experience, and drive business growth .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ddfe0-6e65-434a-b84f-1ebb4e29975d",
   "metadata": {},
   "source": [
    "##  IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd8ddce-0aad-4f6f-9b54-eac8d8428be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a0f90-65fe-48f8-a70d-23acac5d91eb",
   "metadata": {},
   "source": [
    "## Ensure models directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f23c79-0408-43ab-a89e-d300c081c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926212f-a72c-44e0-b1f3-260e806fb883",
   "metadata": {},
   "source": [
    "##   DATA CLASS DEFINITIONS  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1fda92-40e9-42d0-aa98-ff758cd77317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:  # Score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ef1f8-6b26-4659-97ec-685e987a52aa",
   "metadata": {},
   "source": [
    "## LOAD THE DATA    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f944a1-84b2-4478-8590-4609d2157985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Data ---\n",
      "Total reviews loaded: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Loading Data ---\")\n",
    "file_name = 'Books.json'\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "print(\"Total reviews loaded:\", len(reviews))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307127f-424a-40e5-ac59-f865e343f552",
   "metadata": {},
   "source": [
    "## PREPARE THE DATA\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbbefa59-b16b-4c8c-afe0-189133aa346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Data ---\n",
      "Count of Positive reviews (train): 513\n",
      "Count of Negative reviews (train): 513\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing Data ---\")\n",
    "training, test = train_test_split(reviews, test_size=0.2, random_state=42)\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(\"Count of Positive reviews (train):\", train_y.count(Sentiment.POSITIVE))\n",
    "print(\"Count of Negative reviews (train):\", train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a309870-b8d0-4b93-8c2a-b9b467a4972d",
   "metadata": {},
   "source": [
    " ## BAG OF WORDS VECTORIZATION      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e91be049-f58e-42f2-994e-a34fe7344502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vectorizing Data ---\n",
      "Example raw text:\n",
      " I love Debbie! I have read most of her books, she has another winner here. I particularly like books centered around Alaska. My sister lives there, brings her close. Another hit for Debbie.\n",
      "Vectorized representation:\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Vectorizing Data ---\")\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(\"Example raw text:\\n\", train_x[0])\n",
    "print(\"Vectorized representation:\\n\", train_x_vectors[0].toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81818c1-3950-490d-a098-20dd8efdae9c",
   "metadata": {},
   "source": [
    "## TRAINING MODELS   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a32337-563b-422e-84cf-12baf0a0e15f",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4239e646-b8a4-411b-90fb-95d2a59078ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Linear SVM]\n",
      "SVM Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Linear SVM]\")\n",
    "clf_svm = svm.SVC(kernel='linear' , random_state=42)\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "print(\"SVM Prediction for first test sample:\", clf_svm.predict(test_x_vectors[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b1958d6-d8d1-45f8-9e03-ca4cbb4ccf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I purchased the &#34;book&#34; in the Kindle edition as a gamble, given the price of 1.99.  I lost the bet.  Please describe the item as sheet music, for that is what it is.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cabd7-ec08-4011-9146-027993972a7e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a14fc78-c72e-4a1b-b571-d94db2678081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Decision Tree]\n",
      "Decision Tree Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Decision Tree]\")\n",
    "clf_dec = DecisionTreeClassifier(random_state=42)\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "print(\"Decision Tree Prediction for first test sample:\", clf_dec.predict(test_x_vectors[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cac882-3242-41bb-8fb9-79c58fcd3534",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c3e6c5a-7fe5-4aa0-a695-a27c21aaada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Multinomial Naive Bayes]\n",
      "MultinomialNB Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Multinomial Naive Bayes]\")\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(train_x_vectors, train_y)\n",
    "print(\"MultinomialNB Prediction for first test sample:\", clf_nb.predict(test_x_vectors[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5cdab-8fe7-4b10-8f3f-9b4587fc0f7c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5284e6-d2ba-43b8-9337-b33a20c722eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Logistic Regression]\n",
      "Logistic Regression Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Logistic Regression]\")\n",
    "clf_log = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "print(\"Logistic Regression Prediction for first test sample:\", clf_log.predict(test_x_vectors[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a4c60-f5a6-4502-af1c-b5213abdaaa5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da3661c5-6013-4a1d-a83c-57dc9d1dba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Random Forest]\n",
      "Random Forest Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Random Forest]\")\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(train_x_vectors, train_y)\n",
    "print(\"Random Forest Prediction for first test sample:\", clf_rf.predict(test_x_vectors[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b4c3e-0306-4a76-b5f3-dedfea2a10a0",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e49883d-ed9a-4ef3-80af-5a8f3404306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[K-Nearest Neighbors]\n",
      "KNN Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[K-Nearest Neighbors]\")\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_knn.fit(train_x_vectors, train_y)\n",
    "print(\"KNN Prediction for first test sample:\", clf_knn.predict(test_x_vectors[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d64d3b-4b60-40d1-b448-2c4d3540cbdc",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46c93c1e-677b-4921-bc2a-1f31d47861be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SGDClassifier]\n",
      "SGDClassifier Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[SGDClassifier]\")\n",
    "clf_sgd = SGDClassifier(random_state=42)\n",
    "clf_sgd.fit(train_x_vectors, train_y)\n",
    "print(\"SGDClassifier Prediction for first test sample:\", clf_sgd.predict(test_x_vectors[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124db30-3c7d-4d93-8fa0-82a6163d8cd2",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71b34277-7056-472a-b3f9-d8ef86febbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Multi-Layer Perceptron]\n",
      "MLP Prediction for first test sample: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Multi-Layer Perceptron]\")\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=150, random_state=42)\n",
    "clf_mlp.fit(train_x_vectors, train_y)\n",
    "print(\"MLP Prediction for first test sample:\", clf_mlp.predict(test_x_vectors[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c5316-9a9f-405f-9627-e0d6a38f8e75",
   "metadata": {},
   "source": [
    "## EVALUATION METRICS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "311f8d10-c7d4-4304-9dd4-fddf91768ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Models ---\n",
      "\n",
      "[SVM Evaluation]\n",
      "Accuracy = 0.8244\n",
      "Confusion Matrix:\n",
      "[[108  23]\n",
      " [ 23 108]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.82      0.82       131\n",
      "    POSITIVE       0.82      0.82      0.82       131\n",
      "\n",
      "    accuracy                           0.82       262\n",
      "   macro avg       0.82      0.82      0.82       262\n",
      "weighted avg       0.82      0.82      0.82       262\n",
      "\n",
      "\n",
      "[Decision Tree Evaluation]\n",
      "Accuracy = 0.6718\n",
      "Confusion Matrix:\n",
      "[[84 47]\n",
      " [39 92]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.68      0.64      0.66       131\n",
      "    POSITIVE       0.66      0.70      0.68       131\n",
      "\n",
      "    accuracy                           0.67       262\n",
      "   macro avg       0.67      0.67      0.67       262\n",
      "weighted avg       0.67      0.67      0.67       262\n",
      "\n",
      "\n",
      "[MultinomialNB Evaluation]\n",
      "Accuracy = 0.8473\n",
      "Confusion Matrix:\n",
      "[[116  15]\n",
      " [ 25 106]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.89      0.85       131\n",
      "    POSITIVE       0.88      0.81      0.84       131\n",
      "\n",
      "    accuracy                           0.85       262\n",
      "   macro avg       0.85      0.85      0.85       262\n",
      "weighted avg       0.85      0.85      0.85       262\n",
      "\n",
      "\n",
      "[Logistic Regression Evaluation]\n",
      "Accuracy = 0.8321\n",
      "Confusion Matrix:\n",
      "[[108  23]\n",
      " [ 21 110]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.84      0.82      0.83       131\n",
      "    POSITIVE       0.83      0.84      0.83       131\n",
      "\n",
      "    accuracy                           0.83       262\n",
      "   macro avg       0.83      0.83      0.83       262\n",
      "weighted avg       0.83      0.83      0.83       262\n",
      "\n",
      "\n",
      "[Random Forest Evaluation]\n",
      "Accuracy = 0.8206\n",
      "Confusion Matrix:\n",
      "[[106  25]\n",
      " [ 22 109]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.81      0.82       131\n",
      "    POSITIVE       0.81      0.83      0.82       131\n",
      "\n",
      "    accuracy                           0.82       262\n",
      "   macro avg       0.82      0.82      0.82       262\n",
      "weighted avg       0.82      0.82      0.82       262\n",
      "\n",
      "\n",
      "[KNN Evaluation]\n",
      "Accuracy = 0.7061\n",
      "Confusion Matrix:\n",
      "[[88 43]\n",
      " [34 97]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.72      0.67      0.70       131\n",
      "    POSITIVE       0.69      0.74      0.72       131\n",
      "\n",
      "    accuracy                           0.71       262\n",
      "   macro avg       0.71      0.71      0.71       262\n",
      "weighted avg       0.71      0.71      0.71       262\n",
      "\n",
      "\n",
      "[SGDClassifier Evaluation]\n",
      "Accuracy = 0.7977\n",
      "Confusion Matrix:\n",
      "[[101  30]\n",
      " [ 23 108]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.81      0.77      0.79       131\n",
      "    POSITIVE       0.78      0.82      0.80       131\n",
      "\n",
      "    accuracy                           0.80       262\n",
      "   macro avg       0.80      0.80      0.80       262\n",
      "weighted avg       0.80      0.80      0.80       262\n",
      "\n",
      "\n",
      "[MLP Evaluation]\n",
      "Accuracy = 0.8359\n",
      "Confusion Matrix:\n",
      "[[107  24]\n",
      " [ 19 112]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.85      0.82      0.83       131\n",
      "    POSITIVE       0.82      0.85      0.84       131\n",
      "\n",
      "    accuracy                           0.84       262\n",
      "   macro avg       0.84      0.84      0.84       262\n",
      "weighted avg       0.84      0.84      0.84       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Models ---\")\n",
    "models = {\n",
    "    \"SVM\": clf_svm,\n",
    "    \"Decision Tree\": clf_dec,\n",
    "    \"MultinomialNB\": clf_nb,\n",
    "    \"Logistic Regression\": clf_log,\n",
    "    \"Random Forest\": clf_rf,\n",
    "    \"KNN\": clf_knn,\n",
    "    \"SGDClassifier\": clf_sgd,\n",
    "    \"MLP\": clf_mlp\n",
    "}\n",
    "\n",
    "accuracy_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(test_x_vectors)\n",
    "    acc = accuracy_score(test_y, y_pred)\n",
    "    accuracy_scores[name] = acc\n",
    "    print(f\"\\n[{name} Evaluation]\")\n",
    "    print(f\"Accuracy = {acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(test_y, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fd35b-dfc7-4a3d-9077-0c029b33b713",
   "metadata": {},
   "source": [
    "## Determine and display the best model based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31e41424-eda4-47ad-8501-a6064f13562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model from initial training: MultinomialNB with Accuracy = 0.8473\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(accuracy_scores, key=accuracy_scores.get)\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest Model from initial training: {best_model_name} with Accuracy = {accuracy_scores[best_model_name]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8a537-7800-4e89-99d3-76a32baf3035",
   "metadata": {},
   "source": [
    "## SAVE THE BEST MODEL   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e637401c-3092-47b3-939c-d1a4759d3574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best overall model saved as './models/best_sentiment_classifier.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open('./models/best_sentiment_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"\\nBest overall model saved as './models/best_sentiment_classifier.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39cd42e-1572-4814-9a84-8fabdff8e1f0",
   "metadata": {},
   "source": [
    "### Save the TF-IDF vectorizer for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89ec89ec-bbbe-44dc-ac66-8dcea84ab56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizer saved as './models/vectorizer.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open('./models/vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(\"TF-IDF vectorizer saved as './models/vectorizer.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a76e4-be6f-4df5-8dcb-e8fafd0cb283",
   "metadata": {},
   "source": [
    "## MANUAL TEST AND MODEL RELOAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05702515-93d3-4c31-9177-6434ff3a4b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Manual Test After Reloading the Best Model ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Manual Test After Reloading the Best Model ---\")\n",
    "\n",
    "with open('./models/best_sentiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_nb_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15659f9-a19f-4ac3-9480-20b9094d5aef",
   "metadata": {},
   "source": [
    "## Perform manual testing using the reloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30e095af-3ebf-4213-b788-2c7c0bb9ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Test Predictions : ['NEGATIVE' 'POSITIVE' 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "manual_test_set = ['awful, I want a refund', 'fantastic read, couldn’t put it down', 'not as expected, very upset']\n",
    "manual_test_vectors = vectorizer.transform(manual_test_set)\n",
    "manual_predictions = loaded_nb_model.predict(manual_test_vectors)\n",
    "print(\"Manual Test Predictions :\", manual_predictions)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a456510-a656-4092-974c-0019fa3719b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
